runner:
  n_epochs: -1
  total_steps: 1000000
  gradient_clipping: 5.0
  gradient_accumulate_steps: 4

  log_step: 50
  save_step: 5000
  max_keep: 10

  fp16: true

optimizer:
  name: AdamW_with_schedule
  lr: 2.e-4
  warmup_proportion: 0.07
  betas: [0.9, 0.98]
  eps: 1.e-6
  weight_decay: 1.e-6

pretrain_expert:
  datarc:
    num_workers: 2
    train_batch_size: 32
    max_timestep: 0
    libri_root: /data/megastore/Datasets
    file_path: /data/megastore/Projects/DuJing/code/s3prl/s3prl/data/ZhEn_25k
    sets: ['train']
